Сначала запустим кластер Kubernetes. Для этого нужно дождаться выполнения команды:

`./launch_k8s.sh`{{execute}}

Но и это, к сожалению, еще не все. Также мы должны дождаться пока ноды кластера перейдут в статус Ready. Статус можно посмотреть командой:

`kubectl get nodes`{{execute}}

Запускаем кластер Kubernetes, для нам нужно будет немного подождать.

Кластер у нас небольшой, но настоящий - состоит из 2ух нод - одной управляющей ноды и одной рабочей. Давайте зайдем на рабочую ноду. 

`ssh node01 `{{execute T2}}

(если терминал не был до этого открыт, то команду нужно будет нажать 2 раза - первый раз будет открыт терминал, а во второй выполнится уже команда)
 
На всех нодах установлено контейнерное окружение. в нашем случае - это Docker. А также запущены агенты - kubelet и kubeproxy. 

Убедиться в этом мы можем, запуском команды 

на управляющей ноде
`ps -ef | grep /usr/bin/kubelet`{{execute T1}}

на рабочей ноде
`ps -ef | grep /usr/bin/kubelet`{{execute T2}}

Kube-proxy и управляющие компоненты Kubernetes запущены в контейнерном окружении и увидеть их можно с помощью команды docker ps 

на управляющией ноде

`docker ps`{{execute T1}}

на рабочей ноде

`docker ps`{{execute T2}}

`docker ps | grep -v pause`{{execute T1}}

Поскольку эта инсталляция Kubernetes не является минимальной, помимо базовых компонентов, про которые мы с вами говорили, тут присутствую и другие, дополнительные компоненты. 

Как видим, на рабочей ноде нет управлящих компонентов, таких как etcd, kube-scheduler, kube-controller-manager и api-server 

Давайте посмотрим, как компоненты работают. 

Начнем с входной точки для кластера, через которую происходит управление кластером и взаимодействие компонентов.

API-Server

Спроксируем api server на локальный порт 8080 с помощью команды.

`kubectl proxy --port=8080`{{execute T3}}

`./proxy_api_server_to_localhost_8080.sh`{{execute T3}}

(если терминал не был до этого открыт, то команду нужно будет нажать 2 раза - первый раз будет открыт терминал, а во второй выполнится уже команда)

Теперь обращаясь по локальному порту 8080, мы можем совершать запросы к API Server-у.

Например, мы можем получить конфигурацию и состояние кластера, относящуюся к controlplane ноде, сделав запрос:

`curl 127.0.0.1:8080/api/v1/nodes/controlplane/ | jq`{{execute T1}}

В ответ мы получим довольно большой json с информацией о ноде.

Вся эта информация хранится в хранилище etcd. Мы можем зайти etcd c помощью команды docker exec и посмотреть эту конфигурацию. Etcd является key-value хранилищем и, зная ключ, можно получить значение с помощью утилиты etcdctl. Информация о ноде controlplane хранится в ключе "/registry/minions/controlplane". 

`ETCD_DOCKER_ID=$(docker ps | grep -v pause | grep etcd | awk '{print$1}')`{{execute T1}}

`docker exec -it $ETCD_DOCKER_ID etcdctl get /registry/minions/controlplane  --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/peer.crt  --key /etc/kubernetes/pki/etcd/peer.key`{{execute T1}}


Также с помощью этой утилиты можем посмотреть, какие еще есть ключи. Их может быть довольно много, поэтому ограничимся 100 записями.

`docker exec -it $ETCD_DOCKER_ID etcdctl get / --prefix --keys-only --limit=10 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/peer.crt  --key /etc/kubernetes/pki/etcd/peer.key`{{execute T1}}

Через API-Server пользователи кластера (утилиты, человек) или внутренние компоненты кластера получают и обновляют конфигурацию и статус кластера, который хранится, в etcd, а также подписываются на изменения. 

Давайте с вами запустим инстанс сервиса в кластере. Это простейший сервис, который на / отдает hello world. Образ контейнера хранится на dockerhub.  

Для того, чтобы наблюдать, как работают компоненты, давайте с вами подпишемся на события, относящиеся к нашему экземпляру сервиса с помощью такой команды в соседнем терминале:


`while true; do clear ; curl -s 127.0.0.1:8080/api/v1/events  | jq '.items[] | {message: .message, component: .source.component} | select(.message | index("hello"))' ; sleep 3; done`{{execute T4}}

команда будет висеть, и как только будут появлятся события о нашем сервисе, они здесь будут появлятся. 

Для того, чтобы создать рабочую нагрузку, нужно сделать запрос к API Server-у.
Запрос будет выглядеть следующим образом.   

`curl -v -X POST -H "Content-Type: application/json" http://127.0.0.1:8080/api/v1/namespaces/default/pods -d@hello-service.json`{{execute T1}}

Чуть позже мы разберем формат запроса, а сейчас давайте посмотрим, что происходило. 

В событиях мы с вами можем увидеть события от scheduler-а и kubelet-a. 

Также можем с вами увидеть, что на рабочей ноде наш сервис был запущен:

`docker ps | grep -v pause | grep hello`{{execute T2}}


А вот на управлюящей ноде сервиса, конечно, не будет
`docker ps | grep -v pause | grep hello`{{execute T1}}
